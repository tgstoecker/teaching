{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "course_edgeR_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3k-tgq3OuUuj",
        "zUfGXSdgvn8l",
        "7ql6Y5qJwwED",
        "Fr1NK22VU9ek",
        "M1OFp4IY2gsU",
        "POTsr8VPW8GU",
        "68LCNsCyZcvn",
        "HziiMSS5bZYB",
        "jr7OzfFh31oG",
        "zgA0ZIvEc4E9",
        "R-FCSpUqd9GV",
        "GNs5w3BmePq2",
        "l1Y4NA2m41ra",
        "_-Ib89Z_51mR",
        "fwK9KT7yf6Bf",
        "6YGWGYPbgCy5",
        "T2l72X7ugcJl"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNRwRjtPtsTnNrfsu4jsgYL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tgstoecker/teaching/blob/master/AppliedBioinformatics/Notebooks/course_edgeR_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k-tgq3OuUuj",
        "colab_type": "text"
      },
      "source": [
        "# Differential Expression Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA5023sAq-gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "R.Version()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUfGXSdgvn8l",
        "colab_type": "text"
      },
      "source": [
        "##Installation of necessary R packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NQkEiaUluM_7",
        "colab": {}
      },
      "source": [
        "install.packages(\"reshape2\", verbose = TRUE)\n",
        "install.packages(\"RColorBrewer\", verbose = TRUE)\n",
        "install.packages(\"ggplot2\", verbose = TRUE)\n",
        "install.packages(\"statmod\", verbose = TRUE)\n",
        "install.packages(\"gplots\", verbose = TRUE)\n",
        "install.packages(\"BiocManager\", verbose = TRUE)\n",
        "BiocManager::install(version = \"3.9\", ask = FALSE)\n",
        "if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n",
        "  install.packages(\"BiocManager\")\n",
        "BiocManager::install(\"limma\", version = \"3.9\")\n",
        "\n",
        "if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n",
        "  install.packages(\"BiocManager\")\n",
        "BiocManager::install(\"edgeR\", version = \"3.9\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PolFJMIuaQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "library(reshape2)\n",
        "library(limma)\n",
        "library(edgeR)\n",
        "library(ggplot2)\n",
        "library(RColorBrewer)\n",
        "library(gplots)\n",
        "library(statmod)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ql6Y5qJwwED",
        "colab_type": "text"
      },
      "source": [
        "## Count data table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeCnbacd1tcR",
        "colab_type": "text"
      },
      "source": [
        "Under the github link we provided in the exercise sheets you can choose the featureCounts output you or your group generated.  \n",
        "Just exchange its raw data link for the one shown here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxznGe4g5p85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counts <- \"https://raw.githubusercontent.com/tgstoecker/teaching/master/AppliedBioinformatics/B73/gene-level/total_file.count\"\n",
        "fc_res <- read.table(counts, header = T, row.names = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7pNoyV6Tw5_",
        "colab_type": "text"
      },
      "source": [
        "Check the names of your columns and take a look at your table:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQG9pkgblszx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colnames(fc_res)\n",
        "head(fc_res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY_-kKNyT4uL",
        "colab_type": "text"
      },
      "source": [
        "Shorten the column names indicating the samples - e.g.:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lPWDsaFdbrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colnames(fc_res) <- sub(\"_trimmed_sorted.bam\", \"\", colnames(fc_res))\n",
        "colnames(fc_res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr1NK22VU9ek",
        "colab_type": "text"
      },
      "source": [
        "## Data exploration and quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC9mVV9AVAHD",
        "colab_type": "text"
      },
      "source": [
        "For data exploration and visualization, it is useful to work with transformed versions of count data.  \n",
        "This is because the distribution of count values is usually extremely skewed.\n",
        "Log2transformation helps to approximately normalize the distribution.\n",
        "Take a look at your samples and create a histogram - e.g.:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q49PRFkKmX0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ggplot(fc_res, aes(x = B73_con_1)) + \n",
        "  geom_histogram(binwidth = 2000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEu9kXi6VIYc",
        "colab_type": "text"
      },
      "source": [
        "Log base 2 is typically used here as it allows for the conversion back to the original scale:  \n",
        "A difference of 1 on the log base2  scale  corresponds  to  a  fold  change  of  2  on  the  original count scale.  \n",
        "Since  count  values  for  a  gene  can  be  zero  in some conditions, this results in non-finite values which would be excluded in the plots.  \n",
        "An easy way around this is the use of pseudocounts, e.g.  transforming the data by adding e.g. a 1 count everywhere "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhs0Bl1tmYcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pseudoCount = log2(fc_res[, 6:13] + 1)\n",
        "\n",
        "ggplot(pseudoCount, aes(x = B73_con_1)) + \n",
        "  ylab(expression(log[2](count + 1))) +\n",
        "  geom_histogram(colour = \"white\", binwidth = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw-foCjDVXFv",
        "colab_type": "text"
      },
      "source": [
        "Taking a look at the count distribution between samples/replicates counts is useful to assess effects even before filtering and normalization:\n",
        "This can for instance be done with Boxplots\n",
        "In the following we visualize the distribution of the pseoudocounts in all of your samples.\n",
        "\n",
        "Quick recap on boxplots:\n",
        "Boxes are formed with sides at the 25-th and 75-th percentiles of the distribution.  \n",
        "The line within a box represents the median. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wOaGvXamYoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ignore message about IDs\n",
        "df = melt(pseudoCount)\n",
        "df = data.frame(df, Condition = substr(df$variable,1,nchar(as.character(df$variable))-2))\n",
        "\n",
        "ggplot(df, aes(x = variable, y = value, fill = Condition)) + \n",
        "  geom_boxplot() + xlab(\"\") +\n",
        "  ylab(expression(log[2](count + 1))) + \n",
        "  scale_fill_manual(values = c(\"#619CFF\", \"orchid1\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g4wcfGMV1dS",
        "colab_type": "text"
      },
      "source": [
        "Pseudocounts distributions can also be summarized by means of a density plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2xnyEIXvbq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ggplot(df, aes(x = value, colour = variable, fill = variable)) + \n",
        "  ylim(c(0, 0.25)) +\n",
        "  geom_density(alpha = 0.2, size = 1.25) + \n",
        "  facet_wrap(~ Condition) +\n",
        "  theme(legend.position = \"top\") + \n",
        "  xlab(expression(log[2](count + 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqJWRmrrV_mn",
        "colab_type": "text"
      },
      "source": [
        "Create a vector indicating treatment conditions of the samples \n",
        "- logic: columns left to right"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrA8-BH6vmU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "group = c(\"control\", \"control\", \"control\", \"control\", \"drought\", \"drought\", \"drought\", \"drought\")\n",
        "group"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui6hlVphmrvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a DGE list object - the core of using edgeR\n",
        "# For our purposes the DGEList-object should contain matrixes/dataframes of raw counts, group/treatment info as well as gene names \n",
        "?DGEList\n",
        "dge = DGEList(counts = fc_res[, 6:13], group = group, genes = rownames(fc_res))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1OFp4IY2gsU",
        "colab_type": "text"
      },
      "source": [
        "### MA-plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYlR_2Hb20Dg",
        "colab_type": "text"
      },
      "source": [
        "A plot of log-fold change (M-values) vs the log average (A-values)  \n",
        "M-values = log of the ratio of level counts for each gene between two samples  \n",
        "A-values = the average level counts for each gene across the two samples  \n",
        "\n",
        "MA-plots are a useful way of visualizing the \"reproducibility\" between replicates/samples of an experiment.  \n",
        "In other words a MA-plot usually indicates that normalization is needed/ would be appropriate.  \n",
        "In a MA plot, genes with similar expression levels in two samples will appear around the horizontal line (y= 0).  \n",
        "The code also plots a loess fit (in red) - basically a trend in the bias related to the mean expression.  \n",
        " Adapt the following code and compare all replicates in both treatments: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1y5CLDv0bjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = pseudoCount$B73_con_1\n",
        "y = pseudoCount$B73_con_2\n",
        "\n",
        "## compute M-values\n",
        "M = x - y\n",
        "\n",
        "## compute A-values\n",
        "A = (x + y)/2\n",
        "\n",
        "df = data.frame(A, M)\n",
        "\n",
        "p <- ggplot(df, aes(x = A, y = M)) + \n",
        "  geom_point(size = 1.5, alpha = 1/5) +\n",
        "  geom_hline(color = \"blue2\", yintercept = 0) + \n",
        "  stat_smooth(se = FALSE, method = \"loess\", color = \"red\") \n",
        "p +  ggtitle(\"B73_control_1 vs B73_control_2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmEUJb-CW0Xd",
        "colab_type": "text"
      },
      "source": [
        "## Filtering our data \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POTsr8VPW8GU",
        "colab_type": "text"
      },
      "source": [
        "###Transformation of raw read counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BHlttXXmvCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cpm <- cpm(dge)\n",
        "lcpm <- cpm(dge, log=TRUE)\n",
        "\n",
        "# checkout the library sizes of your samples\n",
        "dge$samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2O6UbDNX_o6",
        "colab_type": "text"
      },
      "source": [
        "**B73 based example**  \n",
        "A CPM value of 1 for a gene is equal to having 5.8 counts in the sample with the lowest sequencing depth (B73_con_1, lib.size ~ 5.8 million) or 22 counts in the sample with the greatest sequencing depth (B73_con_3, lib.size ~ 22 million).\n",
        "\n",
        "Log-CPM values are generally very suited for exploratory plots. \n",
        "When you set log=TRUE, the edgeR's cpm *function* adds an offset to the CPM values before conversion to the log2-scale. \n",
        "With default options, this offset is 2/L where 2 is the “prior count” (or offset) and L is the average lib.size in millions, so in other words: the log-CPM values are related to the CPM values by log2(CPM + 2/L). \n",
        "\n",
        "Why?\n",
        "With this calculation we can enssure that any two read-counts with identical CPM values will also have identical log-CPM values. \n",
        " 1. Using such a \"prior count\" we never compute the logarithm of 0\n",
        " 2. This also reduces (here it gets nerdy) the variability of all genes with very low counts by shrinking all the inter-sample log-fold-changes towards 0, which has been shown to be nice for exploratory plotting. \n",
        "\n",
        "Now, imagine a dataset, which average library size is about 50 million, so L approx. 50 and the minimum log-CPM value for each sample becomes log2(2/50) = -4.644. \n",
        "In other words, a count of zero for this data maps to a log-CPM value of -4.644 after adding the \"prior count\".\n",
        "\n",
        "Now check your data/samples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c56KgCGm0XG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L <- mean(dge$samples$lib.size) * 1e-6\n",
        "M <- median(dge$samples$lib.size) * 1e-6\n",
        "c(L, M)\n",
        "summary(lcpm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMxPEBkoYRDY",
        "colab_type": "text"
      },
      "source": [
        "Removing genes that are lowly expressed\n",
        "RNA-Seq datasets will include a mix of genes, some of them expressed and some which are not. \n",
        "For our purposes it is of interest to examine genes that are expressed in one treatment but not in the other. \n",
        "However some genes could be UNexpressed throughout all samples! \n",
        "\n",
        "Are there any genes in your 8 samples that fit this scenario?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXLkce2jnQQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "head(dge$counts)\n",
        "table(rowSums(dge$counts==0)==8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reppr4-YYY0K",
        "colab_type": "text"
      },
      "source": [
        "Why do we care?\n",
        "Genes that do not have a worthwhile number of reads in any sample should be filtered out of the downstream analyses. \n",
        "Biological reason: Genes not expressed at a biologically relevant level in any of our samples/conditions are uninteresting \n",
        "Statistical reason: removal of low count genes reduces statistical \"noise\"; more precisely:\n",
        "estimation of the mean-variance relationship is made more precise and also the number of statistical tests which need to be performed in the subsequent steps for differential expression are reduced. \n",
        "\n",
        "EdgeR has an automatic way to filter our genes, while trying to keep as many as possible which are deemed worthwhile, regarding their counts \n",
        "(it is of course possible to dive deeper and set custom cutoffs etc.).\n",
        "-> for our purposes and most use cases the automatic way is a reasonable choice\n",
        "\n",
        "Now, how does edgeR go about the filtering?\n",
        "The basic idea is to keep all genes which possess a minimum number of counts in a reasonable number of our samples.\n",
        "CPM values instead of raw counts are used as to not give preference to samples with large library sizes as discussed above. \n",
        "E.g. large lib.size leads to lower CPM cutoff;\n",
        "-> larger library sizes (higher resolution) allow for the exploration of more genes at lower expression levels \n",
        "(Usually the function keeps genes with about 10 or more read counts in enough samples) the cutoff can thus be roughly approximated by: log2(10/M + 2/L)\n",
        "\n",
        "To sum up: Determining factors are the library sizes of the samples, the minimum required count and the design of the experiment.\n",
        "\n",
        "For more details see documentation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR4dri3TvnVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?filterByExpr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_EfZCjjYwIH",
        "colab_type": "text"
      },
      "source": [
        "All this already indicates that such filtering is very much experiment specific.\n",
        "But how do we get edgeR/R to understand our data or research question?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNVm-xedY5K1",
        "colab_type": "text"
      },
      "source": [
        "This leads us to another necessary step:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68LCNsCyZcvn",
        "colab_type": "text"
      },
      "source": [
        "##Creating a design matrix "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj9vlrDYiAyz",
        "colab_type": "text"
      },
      "source": [
        "With the data in the course we want to find out which genes are differentially expressed between control and drought treatment. \n",
        "A design matrix of our data is easily created using the sample information.\n",
        "note1: in this simple scenario we only need to make use of the group vector, created at the very beginning of this workflow \n",
        "note2: with ~0 we remove the intercept from our 2 level factor, which we treat as two seperate groups; we don't have any interaction in this simple model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr67NGco0QTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "design <- model.matrix(~0+group)\n",
        "design"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYmSlSfrZbvt",
        "colab_type": "text"
      },
      "source": [
        "Design matrices can be much more complex, which (theoretically) allows you to model every well designed experiment e.g. factorial designs, complex interactions and much, much more are possible\n",
        "\n",
        "Check the column names - these should be your groups of interest?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WFzFdSNoIQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colnames(design)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK7eScGRZ9Z6",
        "colab_type": "text"
      },
      "source": [
        "Now we combine everything previously mentioned and perform edgeR's automatic filtering.\n",
        "Note how well designed edgeR is -\n",
        "Filtering the DGEList-object this way keeps gene and count info for the retained genes correctly associated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-nk5QgroV9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keep <- filterByExpr(dge, design)\n",
        "dge_filtered <- dge[keep, , keep.lib.sizes=FALSE]\n",
        "#the amount of genes after filtering is reduced - how much in your case?\n",
        "dim(dge_filtered)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDTNS-B2aa_x",
        "colab_type": "text"
      },
      "source": [
        "All rows without any counts should definitely have been excluded:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puKGxO-joWDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "table(rowSums(dge_filtered$counts==0)==8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akrlznNMay_x",
        "colab_type": "text"
      },
      "source": [
        "Data exploration also means visualization, so after so much theory let's plot the density distribution before and after filtering.\n",
        "To brush up your R skills: Take your time, go through the code line by line and try to understand what everything does."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxqid11-0Lw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#general setup of the plots\n",
        "par(mfrow=c(1,2))\n",
        "\n",
        "lcpm.cutoff <- log2(10/M + 2/L)\n",
        "\n",
        "# create first plot\n",
        "lcpm_unfiltered <- cpm(dge, log=TRUE)\n",
        "nsamples <- ncol(dge)\n",
        "col <- brewer.pal(nsamples, \"Paired\")\n",
        "plot(density(lcpm_unfiltered[,1]), col=col[1], lwd=2, ylim=c(0,0.35), las=2, main=\"\", xlab=\"\")\n",
        "title(main=\"A. Raw data\", xlab=\"Log-cpm\")\n",
        "abline(v=lcpm.cutoff, lty=3)\n",
        "for (i in 2:nsamples){\n",
        "  den <- density(lcpm_unfiltered[,i])\n",
        "  lines(den$x, den$y, col=col[i], lwd=2)\n",
        "}\n",
        "legend(\"topright\", row.names(dge$samples), text.col=col, bty=\"n\")\n",
        "\n",
        "# create second plot\n",
        "lcpm_filtered <- cpm(dge_filtered, log=TRUE)\n",
        "plot(density(lcpm_filtered[,1]), col=col[1], lwd=2, ylim=c(0,0.35), las=2, main=\"\", xlab=\"\")\n",
        "title(main=\"B. Filtered data\", xlab=\"Log-cpm\")\n",
        "abline(v=lcpm.cutoff, lty=3)\n",
        "for (i in 2:nsamples){\n",
        "  den <- density(lcpm_filtered[,i])\n",
        "  lines(den$x, den$y, col=col[i], lwd=2)\n",
        "}\n",
        "legend(\"topright\", row.names(dge_filtered$samples), text.col=col, bty=\"n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bAUX6eFbBm9",
        "colab_type": "text"
      },
      "source": [
        "You just plotted the density of log-CPM values of all samples before and after filtering!\n",
        "The vertical line in each plot marks the aforementioned, approximated log-CPM threshold used in the filtering step.\n",
        "\n",
        "Based on the inspection and visualization of our data we can conclude that a good amount of genes within each sample are either un-/verylow-expressed as is indicated by the small and negative logCPM values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HziiMSS5bZYB",
        "colab_type": "text"
      },
      "source": [
        "##Normalization (of gene expression distributions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLO3zK6IiOqN",
        "colab_type": "text"
      },
      "source": [
        "With Normalization systemic differences between samples are removed in order to negate the impact of technical bias (in other words: external factors that are not of biological interest) on the final results as much as possible.  \n",
        "Normalization generally entails that an appropriate baseline is determined; sample counts are then expressed relative to this baseline. \n",
        "\n",
        "For robust diff. exp. analysis we want to assume that all samples have a similar range and distribution of expression values. \n",
        "We can make use of various normalization approaches to equalise the expression distributions so that all our samples are similar in this aspect across the entire experiment.\n",
        "\n",
        "Any plot showing the per sample expression distributions, such as a density or boxplot, is useful in determining whether any samples are considerably different to others. \n",
        "Throughout all samples of our data distributions of log-CPM values are already quite similar (as can be seen e.g. in the created density plots)\n",
        "\n",
        "Nevertheless, we are going to perform normalization by the method of trimmed mean of M-values (TMM) -\n",
        "\n",
        "With edgeR this can be performed using the calcNormFactors function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHQhlDNfpCZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dge_normalized <- calcNormFactors(dge_filtered, method = \"TMM\")\n",
        "#have a look at the individual normalization factors of the samples we just created\n",
        "dge_normalized$samples$norm.factors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3aJHIH0bttq",
        "colab_type": "text"
      },
      "source": [
        "These serve as \"scaling factors\" for the individual library sizes.\n",
        "For the data used in the course the effect of TMM-normalisation is rather mild, as can be seen with the norm.factors, which are all relatively close to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afqXFJnnpJvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's plot a comparison of the raw, filtered and normalized sample log-CPM values using boxplots - a.k.a. expression distribution\n",
        "#general setup of the plots\n",
        "par(mfrow=c(1,3), mar = c(9, 3, 3, 3))\n",
        "\n",
        "#first plot - raw\n",
        "lcpm <- cpm(dge, log=TRUE)\n",
        "boxplot(lcpm, las=2, col=col, main=\"\")\n",
        "title(main=\"Raw data\",ylab=\"Log-cpm\")\n",
        "\n",
        "# second plot - un-normalized but filtered\n",
        "lcpm_filtered <- cpm(dge_filtered, log=TRUE)\n",
        "boxplot(lcpm_filtered, las=2, col=col, main=\"\")\n",
        "title(main=\"Unnormalized but \\n filtered data\",ylab=\"Log-cpm\")\n",
        "\n",
        "# second plot - normalized and filtered\n",
        "lcpm_normalized <- cpm(dge_normalized, log=TRUE)\n",
        "boxplot(lcpm_normalized, las=2, col=col, main=\"\")\n",
        "title(main=\"Normalized and \\n filtered data\",ylab=\"Log-cpm\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtDnnNg8b51b",
        "colab_type": "text"
      },
      "source": [
        "As you can see there is not much to see ;)  \n",
        "Thus in order to give a better visual representation of the effects of normalisation, we are going to manually worsen our data a bit.\n",
        "In the code provided below, counts of the 7th sample are reduced to 5% of their original values, and in the 8th sample they are multiplied to be 5-times larger.\n",
        "Please feel free to make it even worse!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-hJqmA90Fwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's repeat the plot (without raw/unfltered data) - but with worsely distributed data - this time concentrating on normalization\n",
        "dge_filtered_worse <- dge_filtered\n",
        "dge_filtered_worse$samples$norm.factors <- 1\n",
        "dge_filtered_worse$counts[,7] <- ceiling(dge_filtered_worse$counts[,1]*0.05)\n",
        "dge_filtered_worse$counts[,8] <- dge_filtered_worse$counts[,2]*5\n",
        "\n",
        "#general setup of the plots\n",
        "par(mfrow=c(1,2))\n",
        "\n",
        "# first plot - un-normalized and worsened\n",
        "lcpm_filtered_worse <- cpm(dge_filtered_worse, log=TRUE)\n",
        "boxplot(lcpm_filtered_worse, las=2, col=col, main=\"\", ylim = c(-5, 15))\n",
        "title(main=\"Unnormalized data \\n (manually worsened)\",ylab=\"Log-cpm\")\n",
        "\n",
        "#again perform normalization - and take a look at the norm.factors here, especially of all samples you altered!\n",
        "dge_filtered_worse_normalized <- calcNormFactors(dge_filtered_worse)  \n",
        "dge_filtered_worse_normalized$samples$norm.factors\n",
        "\n",
        "# second plot - normalized\n",
        "lcpm_filtered_worse_normalized <- cpm(dge_filtered_worse_normalized, log=TRUE)\n",
        "boxplot(lcpm_filtered_worse_normalized, las=2, col=col, main=\"\", ylim = c(-5, 15))\n",
        "title(main=\"Normalized data\",ylab=\"Log-cpm\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXvKw2ULcDuk",
        "colab_type": "text"
      },
      "source": [
        "With the modified data the distributions are decidedly different between before compared to after normalization.  \n",
        "Take special note of the TMM scaling factors of the altered samples – neither of the values should be close to 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr7OzfFh31oG",
        "colab_type": "text"
      },
      "source": [
        "##Data exploration #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgA0ZIvEc4E9",
        "colab_type": "text"
      },
      "source": [
        "###MDS plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8z_XQB9iW3p",
        "colab_type": "text"
      },
      "source": [
        "Another very useful way to inspect data such as ours, is the multi-dimensional scaling (MDS) plot.  \n",
        "The plot shows similarities and dissimilarities between samples in an unsupervised manner, so that one can have an idea of the extent to which differential expression can be detected before carrying out formal tests.   \n",
        "Best case scenario: Samples cluster well within the primary condition of interest, and any sample obviously different from its group could be identified and followed up for sources of error or extra variation.  \n",
        "Generally, technical replicates should lie closest to one another.  \n",
        "\n",
        "To create such a visualization we can use limma's plotMDS function.   \n",
        "The first dimension represents the leading-fold-change that best separates samples and explains the largest proportion of variation; the second dimension having a smaller effect. \n",
        "\n",
        "If samples cluster by a given factor in any of these dimensions, it suggests that the factor contributes to expression differences and is worth including in the linear modelling.  \n",
        "In our case we only have the replicate groups as factors, but one could also look at e.g. the sequencing lanes.  \n",
        "\n",
        "The \"distances\" between points are to be interpreted as the leading log2-fold-change.  \n",
        "It is basically an averaged (root-mean-square) log2-fold-change between the samples for the top genes (largest fold changes) that distinguish these samples.\n",
        "\n",
        "So in order to explore differences between the groups/treatments in an unsupervised manner:  \n",
        "if the legend is on top of points in the plot, then change its location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjH2fMVd0B5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pch <- c(0, 3)\n",
        "colors <- rep(c(\"blue\", \"red\"))\n",
        "plotMDS(dge_normalized, col = colors[dge_normalized$samples$group], pch = pch[dge_normalized$samples$group])\n",
        "legend(\"bottomright\", legend=levels(dge_normalized$samples$group), pch=pch, col=colors, ncol=2)\n",
        "\n",
        "\n",
        "#Please take note, that this kind of analysis would be more conclusive if we were to compare more than just \n",
        "#control vs drought in one of the maize lines.\n",
        "#We will perform it with all data of the course in the venn diagramme script - refer back to the information given here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-FCSpUqd9GV",
        "colab_type": "text"
      },
      "source": [
        "### Return to MD/MA plots\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmexDDLwigb0",
        "colab_type": "text"
      },
      "source": [
        "We can also re-examine the expression profiles of our samples now that we have performed filtering and normalization using limma's plotMD function.  \n",
        "We will produce MD plots that compare samples to artificial reference libraries constructed from the average of all the other samples.  \n",
        "\n",
        "Compared to our pseudocount based MA visualizations now the majority of our points should cluster around the red line -  \n",
        "in other words: a log-ratio of zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kVXkc7qz9z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#control samples\n",
        "par(mfrow=c(2,2))\n",
        "for (i in c(1:4)) {\n",
        "plotMD(dge_normalized, column=i)\n",
        "abline(h=0, col=\"red\", lty=2, lwd=2)\n",
        "}\n",
        "\n",
        "#drought samples\n",
        "for (i in c(5:8)) {\n",
        "  plotMD(dge_normalized, column=i)\n",
        "  abline(h=0, col=\"red\", lty=2, lwd=2)\n",
        "}\n",
        "\n",
        "#To repeat: these plots show the mean-difference of log2-expression in sample x versus the average log2-expression across all other samples of interest (an artificial \"rest\"-library).\n",
        "#Diagonal lines in the lower left of the plots correspond to genes with counts of 0, 1, 2,... in the investigated sample.\n",
        "#Generally speaking, samples with low normalization factors (well below 1) would show log-ratios with an apparent positive skew and vice versa. \n",
        "#However, since our samples all possess norm.factors close around 1, the relationship between skews in the plot and the underlying norm.factor of the respective sample,\n",
        "#is difficult to see at best - it starts to become more clear when log-ratios values of above/below 5/-5 would be visible in the plot."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNs5w3BmePq2",
        "colab_type": "text"
      },
      "source": [
        "##Dispersion estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JarRGpGiwjc",
        "colab_type": "text"
      },
      "source": [
        "EdgeR uses the negative binomial (NB) distribution to model the read counts for each gene in each sample. \n",
        "The dispersion parameter of the NB distribution accounts for variability between biological replicates. \n",
        "\n",
        "In fact three different kind of dispersions are estimated by edgeR:\n",
        " 1. the empirical Bayes moderated dispersion for each individual gene \n",
        " 2. a common dispersion, which is a global dispersion estimate averaged over all genes, \n",
        " 3. a trended dispersion where the dispersion of a gene is predicted from its abundance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epub-M_TpxLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#All 3 dispersion estimates can easily be obtained from the estimateDisp function in one command:\n",
        "dge_disp <- estimateDisp(dge_normalized, design, robust=TRUE)\n",
        "\n",
        "#By this, to the DGEList object additional components (common.dispersion, etc.) are added, which contain the estimated dispersions. \n",
        "#The robust=TRUE option is generally recommended as it protects the empirical Bayes estimates against the impact of extreme/outlier genes with \n",
        "#overproportional large or small individual dispersions.\n",
        "\n",
        "#The dispersion estimates can be visualized with plotBCV:\n",
        "plotBCV(dge_disp)\n",
        "\n",
        "#Here we created a scatterplot of the biological coefficient of variation (BCV) against the average abundance of each individual gene.\n",
        "#The plot shows the square-root estimates of the common, trended and tagwise negative binominal dispersions. \n",
        "#The dispersion trend tends to first decrease smoothly and look asymptotic for genes with larger counts. \n",
        "#It allows depends on the underlying organism/species under investigation."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDc8AOz3e4TT",
        "colab_type": "text"
      },
      "source": [
        "Once negative binomial models are fitted and dispersion estimates are obtained, we could start with the differential expression analysis - using the function exactTest()  \n",
        "However, before that, a second layer or extension of methods can be further employed to consider gene-specific variability from both biological/technical sources.  \n",
        "This is especially reasonable in multifactor experiments and/or when having more than two groups.  \n",
        "For a single factor investigation such as we perform here it is not necessary, however since such simple designs are rarely to be encountered, we will demonstrate the use-case for more complex research.  \n",
        "-> quasi-likelihood (QL) methods  \n",
        "\n",
        "In the QL approach, the negative binominal dispersion trend is used to describe the overall biological variability across all genes.  \n",
        "Also the gene-specific variability different from the overall level is considered by the QL-dispersion.  \n",
        "Note, that in the QL approach, the tagwise/individual negative binominal dispersions are not used.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc7qwCcgz5hG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The estimation of QL dispersions is performed using the glmQLFit function:\n",
        "fit <- glmQLFit(dge_disp, design, robust=TRUE)\n",
        "head(fit$coefficients)\n",
        "\n",
        "#This returns a DGEGLM object (Digital Gene Expression Generalized Linear Model) containing the estimated values of the GLM coefficients for each individual gene. \n",
        "#It also contains several further empirical Bayes statistics including the QL dispersion trend and the squeezed QL dispersion estimates. \n",
        "\n",
        "#Using the plotQLDisp function we can plot the quarter-root QL dispersion against the average abundance of each gene:\n",
        "plotQLDisp(fit)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx9kIb8_4RAe",
        "colab_type": "text"
      },
      "source": [
        "Estimates are shown for the raw (before EB moderation), trended and squeezed (after EB moderation) dispersions.  \n",
        "\n",
        "The raw QL dispersion estimates are squeezed towards a global trend; this reduces the uncertainty of the estimates and improves testing power. \n",
        "The extent of the squeezing is based on variability between genes (most importantly vector \"df.prior\" -> prior degrees of freedom for the QL dispersions):  \n",
        " 1. if QL dispersions are less variable between genes, strong EB moderation is performed \n",
        " 2. if the true unknown dispersions are highly variable, weaker moderation towards the trend is appropriate is performed\n",
        "\n",
        "Setting option robust=TRUE in glmQLFit is again usually recommended.  \n",
        "This allows gene-specific prior df estimates, with lower values for outlier genes and higher values for the main body of genes.  \n",
        "This reduces the chance of getting false positives from genes with extremely high or low raw dispersions, while at the same time increasing statistical power to detect differential expression for the core set of genes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHgn9SL7p3NJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary(fit$df.prior)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1Y4NA2m41ra",
        "colab_type": "text"
      },
      "source": [
        "## We have made it, next up --> testing for differential expression\n",
        "\n",
        "The next step is to test for differential expression between the experimental groups - in our case control vs drought treatment.  \n",
        "For this, first the \"contrast\" has to be created, which corresponds to the comparison we are interested in.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6dXE1Fpzx88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For this we can make use of limma's convenient makeContrasts function:\n",
        "CvsD <- makeContrasts(groupdrought-groupcontrol, levels=design)\n",
        "\n",
        "#In subsequent results, a positive log2-fold-change (logFC) will indicate a gene up-regulated in drought compared to control treated plants, \n",
        "#whereas a negative logFC will indicate a gene more highly expressed in control treated plants.\n",
        "\n",
        "#EdgeR offers two main kinds of tests - QL F-tests and likelihood ratio tests (LRT).\n",
        "#We will use the former as they perform stricter error control by accounting for the uncertainty in dispersion estimation:\n",
        "res <- glmQLFTest(fit, contrast=CvsD)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pschvLbG5BXg",
        "colab_type": "text"
      },
      "source": [
        "*noteworthy:*  \n",
        "Generally speaking, the QL F-test should be used as it far more robust and reliable.  \n",
        "This becomes most apparent when the number of replicates is small.  \n",
        "\n",
        "*in even more detail:*  \n",
        "LRT is typically used for situations in which a dispersion parameter is not used, e.g., logistic regressions or Poisson models.  \n",
        "However, for negative binomial models, the dispersion parameter needs to be estimated from the same data used to fit the model.  \n",
        "This introduces extra uncertainty into the model fit that is not handled by LRT.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2RI3ZO9qH2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Returning to the differential expression analysis\n",
        "#The top diff. exp. genes can be viewed with function topTags:\n",
        "topTags(res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLjBflow5Rye",
        "colab_type": "text"
      },
      "source": [
        "In order to control the **false discovery rate (FDR)**, multiple testing correction is performed using the Benjamini-Hochberg method.  \n",
        "Each locus is tested independently - imagine 20,000 tests being performed and alpha is set to P<0.05.  \n",
        "In this case we could expect at least 1,000 DE loci just by chance (0.05 * 20,000)!  \n",
        "Thus in order to control the false discovery rate, we can make use of control algorithms such as the one by Benjamini and Hochberg.  \n",
        "for a detailed explanation you can have look at: http://www.biostathandbook.com/multiplecomparisons.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19zhItWaqJhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "is.de <- decideTestsDGE(res, adjust.method = \"BH\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHvaXSAKqLcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#summary of the object gives us the amount of diff. exp. genes and also whether they are up/downregulated between conditions\n",
        "summary(is.de)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRhza8Lcqa6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now, using the res object we can add other parameters/cutoffs - by viewing/extracting subsets - thereby determining the set set of genes we are interested in\n",
        "#and extracting all relevant information \n",
        "#e.g. creating a TopTags object with all genes and information on fold changes and p-/q-values\n",
        "check <- topTags(res, adjust.method = \"BH\", n = \"all\")\n",
        "\n",
        "sum(check$table$logFC < 0 & check$table$FDR < 0.05)\n",
        "sum(check$table$logFC > 0 & check$table$FDR < 0.05)\n",
        "\n",
        "subset(check$table, logFC < 0 & FDR < 0.05)\n",
        "subset(check$table, logFC > 0 & FDR < 0.05)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vgh3AWyqi_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#or create lists of upregulated and downregulated genes - from drought perspective\n",
        "edgeR_all_sig_genes <- subset(check$table, FDR < 0.05)$genes\n",
        "up_drought <- subset(check$table, logFC > 0 & FDR < 0.05)$genes\n",
        "down_drought <- subset(check$table, logFC < 0 & FDR < 0.05)$genes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJX0Z5mn5n00",
        "colab_type": "text"
      },
      "source": [
        "The magnitude of the differential expression changes can be visualized with a fitted model MD plot.  \n",
        "in other words:  \n",
        "we visualize the log-fold change and average abundance of each gene.\n",
        "\n",
        "Significantly up and down regulated, differentially expressed genes are highlighted in red and blue, respectively.  \n",
        "Some genes posess high fold changes but are deemed unsignificant due the p-/q-value cutoff/s - e.g. in case of 1 extreme outlier replicate.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM1ONH0WqjI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotMD(res, status=is.de, values=c(1,-1), col=c(\"red\",\"blue\"),\n",
        "       legend=\"topright\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-Ib89Z_51mR",
        "colab_type": "text"
      },
      "source": [
        "###Differential expression above a specified log-fold-change threshold\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHYOgcfTqDUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The easiest way to do this is to add further cutoffs to our subset function\n",
        "subset(check$table, logFC < -1 & FDR < 0.05)\n",
        "subset(check$table, logFC > 1 & FDR < 0.05)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t_v0Nzg57Ov",
        "colab_type": "text"
      },
      "source": [
        "*Sidenote:*  \n",
        "However, if one was to identify very high numbers of differentially expressed genes and wanted to apply more strict methods (in order to shorten the list to \n",
        "those that are biologically more relevant) there exists a better alternative to simply applying cutoffs.  \n",
        "Namely, via the use of a more strict model than that used by glmQLFTest.  \n",
        "This is due to glmQLFTest identifying differential expression based on statistical significance regardless of how small the difference might be.  \n",
        "Using the glmTreat function one can directly perform tests which detect expression changes greater than a specified threshold.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwK9KT7yf6Bf",
        "colab_type": "text"
      },
      "source": [
        "##Visualization of our final diff. exp. results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YGWGYPbgCy5",
        "colab_type": "text"
      },
      "source": [
        "###1- Heat map clustering\n",
        "Heatmaps are a very handy way to display differential expression results.  \n",
        "First convert the read counts into log2-counts-per-million (lcpm) values, as we also did in the beginning of script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxLCIaejzrME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Running dev.off and repeating the code, helps when error messages appear; e.g. if creating heatmap of big size (gene number)\n",
        "lcpm <- cpm(dge_normalized, log=TRUE, prior.count = 1)\n",
        "colnames(lcpm) <- paste(dge_normalized$samples$group, 1:4, sep=\"-\")\n",
        "\n",
        "#Using a heatmap we can display the gene expression pattern across all the samples. \n",
        "#First we select the log2 CPM values for the 2000 top diff. exp. genes based on their p-values as computed in the diff. exp. test \n",
        "#(using all/too many genes may result in your R session crashing depending on the system you are running on):\n",
        "\n",
        "o <- order(res$table$PValue)\n",
        "lcpm <- lcpm[o[1:2000],]\n",
        "\n",
        "lcpm <- lcpm[1:30,]\n",
        "\n",
        "#We produce a heatmap via the coolmap function:\n",
        "coolmap(lcpm, cluster.by = \"de pattern\", margins=c(8,8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oCpOYZr6Mim",
        "colab_type": "text"
      },
      "source": [
        "Coolmap is a great choice since the default clustering metrics are chosen to be appropriate for expression data.  \n",
        "-> It will automatically standardize the expression values  \n",
        "\n",
        "Some notes on interpretation of the colour coded Z-scores:  \n",
        "Simply put, a Z-score represents the number of standard deviations from the mean value of the reference population/all samples.  \n",
        "Z-scores thus inform you where the score lies on a normal distribution curve.  \n",
        "Scores close to zero indicate that the values are exactly average while a score of e.g. +2 tells you that the value is much higher than average.  \n",
        "\n",
        "Genes are clustered by correlation (highly correlated genes are closest).  \n",
        "Samples are clustered, based on Euclidean distance between the expression values of the samples.  \n",
        "Replicate samples from each group should thus be clustered together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2l72X7ugcJl",
        "colab_type": "text"
      },
      "source": [
        "###2-Plotting the volcano\n",
        "Volcano  plots allow for the visual summarization of  both fold-change and statistical significance (generally p-values).  \n",
        "We will create a scatter-plot of the negative (log10 transformed) p-values of our diff. exp. test (y-axis) against the log2 fold change (x-axis).  \n",
        "\n",
        "Even before plotting we can think about where the regions of interest in such a graph are:  \n",
        "Points at the top of the plot possess small p-values thus being highly significant.  \n",
        "Points being far away from the center (left or right) display the largest fold changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp4zwGmBzmSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Let's start of by defining cutoffs for both the p-values and the log2 fold changes, e.g.:\n",
        "lfc = 1\n",
        "pval = 0.05\n",
        "\n",
        "#We then create a smaller dataframe that contains our transformed p-values and the log2 fold changes of the respective genes:\n",
        "tab = data.frame(logFC = res$table$logFC, negLogPval = -log10(res$table$PValue))\n",
        "head(tab)\n",
        "\n",
        "#next, we plot the basics\n",
        "par(mar = c(5, 4, 4, 4))\n",
        "plot(tab, pch = 16, cex = 0.6, \n",
        "     xlab = expression(log[2]~fold~change),ylab = expression(-log[10]~pvalue),\n",
        "     xlim = c(-4,4))\n",
        "\n",
        "#This already quite good and informative but we can still greatly improve it   \n",
        "signGenes = (abs(res$table$logFC) > lfc & tab$negLogPval > -log10(pval))\n",
        "points(tab[signGenes, ], pch = 16, cex = 0.8, col = \"red\")\n",
        "abline(h = -log10(pval), col = \"green3\", lty = 2)\n",
        "abline(v = c(-lfc, lfc), col = \"blue\", lty = 2)\n",
        "mtext(paste(\"pval =\", pval), side = 4, at = -log10(pval), cex = 0.8, line = 0.5, las = 1)\n",
        "mtext(c(paste(\"-\", lfc, \"fold\"), paste(\"+\", lfc, \"fold\")), side = 3, at = c(-lfc, lfc),cex = 0.8, line = 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKHQmoED6Xdr",
        "colab_type": "text"
      },
      "source": [
        "Red points indicate all genes having both fold-changes greater than our cutoff (x-axis) and high statistical significance (y-axis).  \n",
        "The green line shows the p-value cutoff with points above the line having a p-value < 0.05 and points below the line having a p-value > 0.05.  \n",
        "The vertical lines in blue colour show 1-fold changes.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HHEonc5zidk",
        "colab_type": "text"
      },
      "source": [
        "##Some final thoughts\n",
        "Another important takeaway here is that even with base R and a bit of imagination extremely informative plots can be generated!  \n",
        "\n",
        "To make all your future plots and graphs pretty, you can use the following link showcasing all colour option in base R :D \n",
        "http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf"
      ]
    }
  ]
}